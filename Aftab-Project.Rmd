---
title: "Text Analysis"
author: "Aftab"
date: '2022-05-02'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

The motivation behind this dataset comes from my fondness of the [Rick and Morty](https://www.adultswim.com/videos/rick-and-morty) show. It is a sci-fi cartoon show that primarily revolves around an old drunk cynical scientist (Rick) and his good-hearted grandson (Morty) who travel together across the multiverse for adventures. The show is a comic and delivers the viewvers with dark comedy and a plethora of emotions.

The main characters of the show are Rick, Morty, Summer (granddaughter), Jerry (Son-in-law), Beth (Daughter).

Although, I will be conducting sentiment analysis on these main characters primarily, however, I will be more focusing on my following hypothesis:

**Is Morty’s character driven by fear in the famous Rick and Morty show?**

Having seen the show multiple times, I have noticed that Morty's character is primarily driven by fear, however, I would like to test this hypothesis using some of the sentiment analysis tools. 

## Data

The data comes from [Kaggle](https://www.kaggle.com/datasets/andradaolteanu/rickmorty-scripts). It was initially scraped by Gabriel Harnandes and cleaned by Andrada Olteanu. 
 
I have uploaded the data to my [GitHub](https://github.com/Aftab1995/DS3) repo and sourced it from there for my analysis.
The dataset has following columns:

1. index: just the index of the row
2. season no: The season number of the dialogue
3. episode no: The episode number of the dialogue
4. episode name: The name of the episode
5. name: the character name
6. line: the dialogue of the character

```{r message=FALSE, warning=FALSE, include=TRUE}
# Loading the libraries
library(tidyverse)
library(tidytext)
library(kableExtra)
library(ggplot2)
library(stringr)
#install.packages("textclean")
library(textclean)
library(tm)
library(wordcloud)
library(wordcloud2)
library(RColorBrewer)
library(reshape2)
#install.packages("magick")
library(circlize)
library(magick)
library(gridExtra)
library(grid)
```


```{r message=FALSE, warning=FALSE, include=TRUE}
# Loading the data from Github

data<-read.csv(url('https://raw.githubusercontent.com/Aftab1995/DS3/main/Dataset/RickAndMortyScripts.csv'),encoding="UTF-8")
```

## EDA

Checking to see if there are any missing data in the dataset using the following code. 
We can confirm that we don't have any missing values in our dataset so we can proceed with EDA.
```{r message=FALSE, warning=FALSE}
# Checking for any missing values
to_filter <- sapply(data, function(x) sum(is.na(x)))
to_filter[to_filter > 0]
```


To understand more about the data, I have grouped together the total number of lines spoken by each character in every season of the show and narrowed down the list to top 10. As expected, the highest number of lines are by Rick followed by Morty. As the name of the show suggests, these two are the main characters and their total number of lines far excceeds others'.
```{r message=FALSE, warning=FALSE}

# Looking at the top 10 number of lines by character in all the seasons together

data %>% 
  group_by(Character = name) %>% 
  summarise(Total.Lines = n()) %>% 
  arrange(desc(Total.Lines)) %>%
  head(10) %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
  
```

I then wanted to look at the number of lines for each character by season. So I created three tables, one for each season to retrieve the top 10 characters along with their lines. I then fully joined these tables to not loose out information on characters that only appear in one of the seasons. Then, in order to visualize the results, I gathered the table so that I could use it for ggplot function.

Looking at the bar plot overall, it is synonymous to the table above in terms of total lines. However, when we look at it from season perspective, season 2 stand out. There seems to be a tie between the total number of lines by Rick and Beth, which is followed by a seemingly tie between the number lines by Morty and Jerry. 

We can also see from the plot that for some characters, they only appear in one season only, reason being that either they did not appear in the season at all or their number of lines was not enough to be in the top 10 for that particular season. 

For season 3, Pickle Rick is also in top 10, reason being that there was a whole episode dedicated to this character where Rick turns himself into a pickle to prove his might, one of my favorite episodes. He builds himself a full body armour by killing sewer rats and cockroaches while being a pickle.  


```{r message=FALSE, warning=FALSE}
# Looking at the top 10 characters by season 

# Season 1
s1_lines <- data %>% 
  filter(season.no. == 1) %>% 
  group_by(Character = name) %>% 
  summarise(Total.Lines.S1 = n()) %>% 
  arrange(desc(Total.Lines.S1)) %>%
  head(10) 

# Season 2
s2_lines <- data %>% 
  filter(season.no. == 2) %>% 
  group_by(Character = name) %>% 
  summarise(Total.Lines.S2 = n()) %>% 
  arrange(desc(Total.Lines.S2)) %>%
  head(10) 

# Season 3
s3_lines <- data %>% 
  filter(season.no. == 3) %>% 
  group_by(Character = name) %>% 
  summarise(Total.Lines.S3 = n()) %>% 
  arrange(desc(Total.Lines.S3)) %>%
  head(10) 

lines <- full_join(s1_lines,s2_lines,by="Character")
lines <- full_join(lines,s3_lines,by = "Character")


lines <- gather(lines, "season", "lines", 2:4)

lines <- arrange(lines, "lines")

ggplot(lines) +
  aes(x = reorder(Character, -lines), fill = season, weight = lines) +
  geom_bar() +
  labs(
    x = "Character Name",
    y = "Number of Lines",
    title = "Character Lines by Season"
  ) +  
  ggthemes::theme_economist() +
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 15L,
    face = "bold",
    hjust = 0.5
    ),
    panel.grid.minor = element_line(color = "white",
                                        size = 0.2,
                                        linetype = 1),
    legend.background = element_rect(color = "black", fill = "#9bff16", linetype = "solid"),
    axis.title.y = element_text(margin=margin(r=5))) + 
    ylim(0, 450) + coord_flip()

```

## Data Engineering

Before moving onto the sentiment analysis, it is important to make some changes to the data, such as removing punctuation and stop words from the text. Although, 'unnest_tokens' function in 'tidytext' removes punctuation and converts the text into lower case, I want to remove punctuation prior to applying the 'unnest_tokens' function to make sure I get rid of all them, in case the 'unnest_tokens' leaves behind some, such as "—".


Here, I am removing contractions in the script such as converting 'didn't' into 'did not'. I am using the function 'replace_contraction' from the the library 'textclean'. I have combined the function 'lapply' with 'replace_contraction' to remove contractions from each line in the 'line' column. 
```{r message=TRUE, warning=FALSE}
# Removing contractions and replacing with full words

data$line <- lapply(data$line, replace_contraction)

```

Here I am removing punctuation from the script using the function 'removePunctuation' from the library 'tm'. However, it did not remove "—", hence I used a for loop with 'gsub' to remove it. 
```{r message=TRUE, warning=FALSE}
# Removing any punctuation from the lines

data$line <- lapply(data$line, removePunctuation)

# Removing — from the script

for (i in 1:length(data$line)) {
  data$line[i] <- gsub("—","",data$line[i])
}

```

## Sentiment Analysis

Tokenizing the lines and storing it in a new table to remove stop words and use it further ahead for analysis. The total number of words after tokenizing was around 26000, however, it dropped down to around 8000 after removing the stop words. 
```{r message=TRUE, warning=FALSE}
tokens <- data %>% 
  mutate(line = as.character(line)) %>%  
  group_by(name) %>% 
  unnest_tokens(word, line) 

tokens %>% head(5)

tokens <-  anti_join(tokens,stop_words)

```

Using the tokenized words to visualize Morty's emotions using the [NRC](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8640.2012.00460.x) lexicon. I am using NRC lexicon because unlike some other lexicons, such as Bing or AFINN, it gives us emotions based on its word dictionary. Whereas, Bing and AFINN only provide us positive and negative sentiments. 

Looking at the plot below, it seems like Morty's character is primarily not driven by fear but negativity. However, the character is often driven by fear as it stand at around third position in terms of highest emotions.
```{r message=TRUE, warning=TRUE}

to_plot <- tokens %>% 
  #get 'bing' and filter the data
  inner_join(get_sentiments("nrc")) %>% 
  filter(name == "Morty") %>% 
  #sum number of words per sentiment and character
  count(sentiment, name) %>% 
  group_by(name, sentiment) %>% 
  summarise(sentiment_sum = sum(n)) %>% 
  ungroup()

myColors = c("Morty" = "#f5f505", "anger" = "#FA8072", "anticipation" = "#04700A", "disgust" = "#99F1EB", "fear" = "#F39C12", "joy" = "#D7DBDD", "negative" = "#06060a", "positive" = "#062D82", "sadness" = "#546e3f", "surprise" = "#2ef24f", "trust" = "#3e2ef2" )

# The Chord Diagram  
circos.clear()
circos.par(gap.after = c(rep(2, length(unique(to_plot[[1]])) - 1), 15,
                         rep(2, length(unique(to_plot[[2]])) - 1), 15), gap.degree=2)


chordDiagram(to_plot,grid.col = myColors, transparency = 0.4, annotationTrack = c("name", "grid"),
             annotationTrackHeight = c(0.01, 0.02))
title("What is Morty's character driven by?")

#Add a dope image on the plot
image <- image_read("Morty.jpg")
grid.raster(image, x=0.92, y=0.22, height=0.25)
```

